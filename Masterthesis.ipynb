{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Masterthesis",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgm24yDcmgwU6u8ZYyt650",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahSeo74/Leanrning-project/blob/master/Masterthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx6zwpet7ohx"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWgm-kmd-RxS"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LTZzA1m-Y5v"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdN02GJOk3X-",
        "outputId": "1dfca1c3-542b-46d5-cef7-3ae47239eb97"
      },
      "source": [
        "pip install --user -U nltk"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: nltk in /root/.local/lib/python3.7/site-packages (3.5)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDgFcNt8lJ4-"
      },
      "source": [
        "import re"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOCnLRO1oKiM"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWJFXQMgluin"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6o_2XU4pChX",
        "outputId": "ae279ede-539d-493c-be89-c299cb36a489"
      },
      "source": [
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO6J0inUzXpx",
        "outputId": "4a17c272-a6d1-43a7-c148-65f8957513e2"
      },
      "source": [
        " nltk.download('punkt')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D67NGZj6qHLx"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvYx5O2npBz"
      },
      "source": [
        "import string"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmmo2DOIJpqx",
        "outputId": "894dd229-ca2e-497d-e242-dc299263c7c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW4JkGuzJ_qk",
        "outputId": "a996e825-eb76-4a07-d144-44cef451e415"
      },
      "source": [
        "with open(r'/content/gdrive/My Drive/tweets_data.csv','r',encoding = \"ISO-8859-1\") as file:\n",
        "  train_data =[]\n",
        "  for line in file.readlines():\n",
        "    train_data.append(line.split(','))\n",
        "print(train_data[4])\n"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3', '4', '0', '#model   i love u take with u all the time in urÃ°Â\\x9fÂ\\x93Â±!!! Ã°Â\\x9fÂ\\x98Â\\x99Ã°Â\\x9fÂ\\x98Â\\x8eÃ°Â\\x9fÂ\\x91Â\\x84Ã°Â\\x9fÂ\\x91Â\\x85Ã°Â\\x9fÂ\\x92Â¦Ã°Â\\x9fÂ\\x92Â¦Ã°Â\\x9fÂ\\x92Â¦  \\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpNeYpMWgreO",
        "outputId": "f86dd851-1610-4241-cc59-efe3a6ef75f7"
      },
      "source": [
        "train_tweet=[]\n",
        "i=1\n",
        "for i in range(len(train_data)):\n",
        "  train_tweet.append(train_data[i][3])\n",
        "print(train_tweet[4])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#model   i love u take with u all the time in urÃ°ÂÂÂ±!!! Ã°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂÃ°ÂÂÂ¦Ã°ÂÂÂ¦Ã°ÂÂÂ¦  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZQQrmQMwZ6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6d4171-6e21-4549-bb10-fe0490e473af"
      },
      "source": [
        "train_tweet_str=\",\".join(train_tweet)\n",
        "train_tweet=sent_tokenize(train_tweet_str)\n",
        "train_tweet_word=word_tokenize(train_tweet_str)\n",
        "\n",
        "print(train_tweet_word[0:100])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tweet', ',', '@', 'user', 'when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run', ',', '@', 'user', '@', 'user', 'thanks', 'for', '#', 'lyft', 'credit', 'i', 'ca', \"n't\", 'use', 'cause', 'they', 'do', \"n't\", 'offer', 'wheelchair', 'vans', 'in', 'pdx', '.', '#', 'disapointed', '#', 'getthanked', ',', 'bihday', 'your', 'majesty', ',', '#', 'model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urÃ°Â\\x9fÂ\\x93Â±', '!', '!', '!', 'Ã°Â\\x9fÂ\\x98Â\\x99Ã°Â\\x9fÂ\\x98Â\\x8eÃ°Â\\x9fÂ\\x91Â\\x84Ã°Â\\x9fÂ\\x91Â', 'Ã°Â\\x9fÂ\\x92Â¦Ã°Â\\x9fÂ\\x92Â¦Ã°Â\\x9fÂ\\x92Â¦', ',', 'factsguide', ':', 'society', 'now', '#', 'motivation', ',', '[', '2/2', ']', 'huge', 'fan', 'fare', 'and', 'big', 'talking', 'before', 'they', 'leave', '.', 'chaos', 'and', 'pay', 'disputes', 'when']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-JQUt4cdm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5ace1c-8dda-4f1c-ed4b-9596e3a7b5fb"
      },
      "source": [
        "def to_lower(word): \n",
        "     result =[word.lower() for word in word] \n",
        "     return result\n",
        "     #like Tweet, TWEET, tweet are same #\n",
        "train_tweet_word=to_lower(train_tweet_word)\n",
        "print(train_tweet_word[0:100])"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tweet', ',', '@', 'user', 'when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run', ',', '@', 'user', '@', 'user', 'thanks', 'for', '#', 'lyft', 'credit', 'i', 'ca', \"n't\", 'use', 'cause', 'they', 'do', \"n't\", 'offer', 'wheelchair', 'vans', 'in', 'pdx', '.', '#', 'disapointed', '#', 'getthanked', ',', 'bihday', 'your', 'majesty', ',', '#', 'model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urã°â\\x9fâ\\x93â±', '!', '!', '!', 'ã°â\\x9fâ\\x98â\\x99ã°â\\x9fâ\\x98â\\x8eã°â\\x9fâ\\x91â\\x84ã°â\\x9fâ\\x91â', 'ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦', ',', 'factsguide', ':', 'society', 'now', '#', 'motivation', ',', '[', '2/2', ']', 'huge', 'fan', 'fare', 'and', 'big', 'talking', 'before', 'they', 'leave', '.', 'chaos', 'and', 'pay', 'disputes', 'when']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znQuFADre02d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKRopM7Ycwhf",
        "outputId": "d744daaf-0227-46e0-8b0c-145e19a202ef"
      },
      "source": [
        "def remove_mentions(word):       \n",
        "    result = [re.sub(r\"@\\S+\", \"\", word) for word in word]\n",
        "    result = [re.sub(r\"\\n\", \"\", word) for word in word]\n",
        "    result = [re.sub(r\"â\", \"\", word) for word in word]\n",
        "    result = [re.sub(r\"\\Ã°.*\", \"\", word) for word in word] #replace @\\S with space(\"\")    \n",
        "    return result\n",
        "\n",
        "train_tweet_word=remove_mentions(train_tweet_word)\n",
        "print(train_tweet_word[0:100])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tweet', ',', '@', 'user', 'when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#', 'run', ',', '@', 'user', '@', 'user', 'thanks', 'for', '#', 'lyft', 'credit', 'i', 'ca', \"n't\", 'use', 'cause', 'they', 'do', \"n't\", 'offer', 'wheelchair', 'vans', 'in', 'pdx', '.', '#', 'disapointed', '#', 'getthanked', ',', 'bihday', 'your', 'majesty', ',', '#', 'model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urã°â\\x9fâ\\x93â±', '!', '!', '!', 'ã°â\\x9fâ\\x98â\\x99ã°â\\x9fâ\\x98â\\x8eã°â\\x9fâ\\x91â\\x84ã°â\\x9fâ\\x91â', 'ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦', ',', 'factsguide', ':', 'society', 'now', '#', 'motivation', ',', '[', '2/2', ']', 'huge', 'fan', 'fare', 'and', 'big', 'talking', 'before', 'they', 'leave', '.', 'chaos', 'and', 'pay', 'disputes', 'when']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQaSByQHeF5d",
        "outputId": "6e49aeef-cf61-49e4-a11f-5270e2e7a892"
      },
      "source": [
        "def remove_special_characters(word):       \n",
        "    result = [word.translate(str.maketrans(dict.fromkeys(string.punctuation)))for word in word]#remove special character    \n",
        "    return result\n",
        "\n",
        "train_tweet_word =remove_special_characters(train_tweet_word) \n",
        "print(train_tweet_word[0:100]) \n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tweet', '', '', 'user', 'when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '', '', 'run', '', '', 'user', '', 'user', 'thanks', 'for', '', 'lyft', 'credit', 'i', 'ca', 'nt', 'use', 'cause', 'they', 'do', 'nt', 'offer', 'wheelchair', 'vans', 'in', 'pdx', '', '', 'disapointed', '', 'getthanked', '', 'bihday', 'your', 'majesty', '', '', 'model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urã°â\\x9fâ\\x93â±', '', '', '', 'ã°â\\x9fâ\\x98â\\x99ã°â\\x9fâ\\x98â\\x8eã°â\\x9fâ\\x91â\\x84ã°â\\x9fâ\\x91â', 'ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦', '', 'factsguide', '', 'society', 'now', '', 'motivation', '', '', '22', '', 'huge', 'fan', 'fare', 'and', 'big', 'talking', 'before', 'they', 'leave', '', 'chaos', 'and', 'pay', 'disputes', 'when']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm6-uBgRMzhX",
        "outputId": "c7c6944d-e624-4852-8454-7d05c13eb37e"
      },
      "source": [
        "def remove_stop_words(words):\n",
        "  \n",
        "  stoplist = set(stopwords.words(\"english\")) #tuple need \n",
        "  #for word in words:\n",
        "    #words=word.lower()\n",
        "  #words=text_to_word_sequence(words)\n",
        "  result =[]\n",
        "  for word in words:\n",
        "    if word not in stoplist:\n",
        "      result.append(word)\n",
        "  return result\n",
        "        \n",
        "train_tweet_word= remove_stop_words(train_tweet_word)\n",
        "print(train_tweet_word[0:100])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tweet', '', '', 'user', 'father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', '', '', 'run', '', '', 'user', '', 'user', 'thanks', '', 'lyft', 'credit', 'ca', 'nt', 'use', 'cause', 'nt', 'offer', 'wheelchair', 'vans', 'pdx', '', '', 'disapointed', '', 'getthanked', '', 'bihday', 'majesty', '', '', 'model', 'love', 'u', 'take', 'u', 'time', 'urã°â\\x9fâ\\x93â±', '', '', '', 'ã°â\\x9fâ\\x98â\\x99ã°â\\x9fâ\\x98â\\x8eã°â\\x9fâ\\x91â\\x84ã°â\\x9fâ\\x91â', 'ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦ã°â\\x9fâ\\x92â¦', '', 'factsguide', '', 'society', '', 'motivation', '', '', '22', '', 'huge', 'fan', 'fare', 'big', 'talking', 'leave', '', 'chaos', 'pay', 'disputes', 'get', '', '', 'allshowandnogo', '', '', 'user', 'camping', 'tomorrow', '', 'user', '', 'user', '', 'user', '', 'user', '', 'user', '', 'user', '', 'user', 'dannyã¢â\\x80â¦', '', 'next', 'school']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMLBqaOtfVlF",
        "outputId": "a8d6a46d-a810-4431-ee52-341fcb114e33"
      },
      "source": [
        "def remove_hyperlink(word):       \n",
        "  #result = [re.sub(r\"@\\S+\", \"\", word) for word in word]\n",
        "    return [re.sub(r\"http\\S+\",\"\", word) for word in word] # remove URL\n",
        "remove_hyperlink(train_tweet_word)\n",
        "print(train_tweet_word)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S5DifhQcmUK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVglYcwTfdKz"
      },
      "source": [
        ""
      ],
      "execution_count": 165,
      "outputs": []
    }
  ]
}